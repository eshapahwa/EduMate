import os
import google.generativeai as genai
from dotenv import load_dotenv

load_dotenv()
api_key = os.getenv("GEMINI_API_KEY")
genai.configure(api_key=api_key)

# Use Gemini Pro for text-based reasoning
model = genai.GenerativeModel("gemini-2.0-flash-thinking-exp-01-21")

def ask_llm(prompt: str) -> str:
    try:
        response = model.generate_content(prompt)
        return response.text.strip()
    except Exception as e:
        print("âŒ Gemini Error:", e)
        return "Error generating response."
